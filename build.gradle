plugins {
  id 'java'
  id 'net.saliman.properties' version '1.5.2'
  id 'com.github.johnrengelman.shadow' version '7.1.2'
  id "com.marklogic.ml-gradle" version "4.5.1"
}

group 'org.example'
version '1.0-SNAPSHOT'

java {
  sourceCompatibility = 1.8
  targetCompatibility = 1.8
}

repositories {
  mavenCentral()
}

dependencies {
  compileOnly 'org.apache.spark:spark-sql_2.12:3.4.0'
  implementation "com.marklogic:marklogic-client-api:6.2.0"

  // Makes it possible to use lambdas in Java 8 to implement Spark's Function1 and Function2 interfaces
  // See https://github.com/scala/scala-java8-compat for more information
  implementation("org.scala-lang.modules:scala-java8-compat_2.12:1.0.2") {
    // Prefer the Scala libraries used within the user's Spark runtime.
    exclude module: "scala-library"
  }

  testImplementation 'org.apache.spark:spark-sql_2.12:3.4.0'
  testImplementation 'com.marklogic:marklogic-junit5:1.3.0'
  testImplementation "ch.qos.logback:logback-classic:1.3.5"
  testImplementation "org.slf4j:jcl-over-slf4j:1.7.36"
  testImplementation "org.skyscreamer:jsonassert:1.5.1"
}

test {
  useJUnitPlatform()
  // Allows mlHost to override the value in gradle.properties, which the test plumbing will default to.
  environment "mlHost", mlHost
}

shadowJar {
  // "all" is the default; no need for that in the connector filename.
  archiveClassifier.set("")

  // Spark uses an older version of OkHttp; see
  // https://stackoverflow.com/questions/61147800/how-to-override-spark-jars-while-running-spark-submit-command-in-cluster-mode
  // for more information on why these are relocated.
  relocate "okhttp3", "com.marklogic.okhttp3"
  relocate "okio", "com.marklogic.okio"
}

task perfTest(type: JavaExec) {
  main = "com.marklogic.spark.reader.PerformanceTester"
  classpath = sourceSets.test.runtimeClasspath
  args mlHost
}

task dockerUp(type: Exec) {
  description = "Creates and starts a 3 node MarkLogic cluster."
  commandLine "docker-compose", "up", "-d", "--build"
}

task dockerBuildCache(type: Exec) {
  description = "Creates an image named 'marklogic-spark-cache' containing a cache of the Gradle dependencies."
  commandLine 'docker', 'build', '--no-cache', '-t', 'marklogic-spark-cache', '.'
}

task dockerTest(type: Exec) {
  description = "Run all of the tests within a Docker environment."
  commandLine 'docker', 'run',
    // Allows for communicating with the MarkLogic cluster that is setup via docker-compose.yaml.
    '--network=marklogic_spark_external_net',
    // Map the project directory into the Docker container.
    '-v', getProjectDir().getAbsolutePath() + ':/root/project',
    // Working directory for the Gradle tasks below.
    '-w', '/root/project',
    // Remove the container after it finishes running.
    '--rm',
    // Use the output of dockerBuildCache to avoid downloading all the Gradle dependencies.
    'marklogic-spark-cache:latest',
    'gradle', '-i', '-PmlHost=bootstrap_3n.local', 'test'
}

task dockerPerfTest(type: Exec) {
  description = "Run PerformanceTester a Docker environment."
  commandLine 'docker', 'run',
    '--network=marklogic_spark_external_net',
    '-v', getProjectDir().getAbsolutePath() + ':/root/project',
    '-w', '/root/project',
    '--rm',
    'marklogic-spark-cache:latest',
    'gradle', '-i', '-PmlHost=bootstrap_3n.local', 'perfTest'
}
