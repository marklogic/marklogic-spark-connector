{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the MarkLogic connector available to the underlying PySpark application.\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars \"marklogic-spark-connector-2.3.0.jar\" pyspark-shell'\n",
    "\n",
    "# Define the connection details for the getting-started example application.\n",
    "client_uri = \"spark-example-user:password@localhost:8003\"\n",
    "\n",
    "# Initialize a Spark session.\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd628cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a DataFrame and view the first row.\n",
    "\n",
    "df = spark.read.format(\"marklogic\") \\\n",
    "    .option(\"spark.marklogic.client.uri\", client_uri) \\\n",
    "    .option(\"spark.marklogic.read.opticQuery\", \"op.fromView('example', 'employee', '')\") \\\n",
    "    .option(\"spark.marklogic.read.numPartitions\", 1) \\\n",
    "    .load()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate several operations being pushed down to MarkLogic.\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "df.filter(\"HiredDate < '2020-01-01'\") \\\n",
    "  .groupBy(\"State\", \"Department\") \\\n",
    "  .count() \\\n",
    "  .orderBy(desc(\"count\")) \\\n",
    "  .limit(10) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7058823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group employees by State and then calculate the max base salary across each department, sorting on \n",
    "# the max base salary in the Engineering department. Then plot the data by converting the Spark DataFrame to \n",
    "# a pandas DataFrame - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html . \n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "df.groupBy(\"State\") \\\n",
    "  .pivot(\"Department\") \\\n",
    "  .max(\"BaseSalary\") \\\n",
    "  .orderBy(desc(\"Engineering\")) \\\n",
    "  .limit(10) \\\n",
    "  .toPandas() \\\n",
    "  .plot(kind=\"bar\", title=\"Max Base Salaries Across Departments By State\", x=0, ylabel=\"Max Base Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the above example, but write the results as new documents to MarkLogic.\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "df.groupBy(\"State\") \\\n",
    "  .pivot(\"Department\") \\\n",
    "  .max(\"BaseSalary\") \\\n",
    "  .orderBy(desc(\"Engineering\")) \\\n",
    "  .write \\\n",
    "  .format(\"com.marklogic.spark\") \\\n",
    "  .option(\"spark.marklogic.client.uri\", client_uri) \\\n",
    "  .option(\"spark.marklogic.write.permissions\", \"rest-reader,read,rest-writer,update\") \\\n",
    "  .option(\"spark.marklogic.write.collections\", \"state-base-salaries\") \\\n",
    "  .option(\"spark.marklogic.write.uriTemplate\", \"/state-base-salary/{State}.json\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()\n",
    "\n",
    "print(\"Finished writing documents to MarkLogic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
